{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-mobilenetV2alpha1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1QxlPkFKYH41vuNKHbY1bp-8DR-iCC5nU",
      "authorship_tag": "ABX9TyPOgSo3o7fpGo+EWImoNUex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scalable-DNN/pretrained-models/blob/main/cifar10_mobilenetV2alpha1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILLoTQg4KDon",
        "outputId": "38e2f82a-b9f8-4634-be0a-6181a011ab39"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb  5 14:43:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J2tmSEgH_EV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16110b2f-7578-4960-e6d1-28aa451e640e"
      },
      "source": [
        "!pip install larq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting larq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/60/5fb36a5a4a272e5214963c891dce9eb6bf2222a0fb90178b9e8dd25d4e37/larq-0.10.3-py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 51kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from larq) (0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from larq) (1.19.5)\n",
            "Collecting terminaltables>=3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Requirement already satisfied: importlib-metadata<4.0,>=2.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from larq) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4.0,>=2.0; python_version < \"3.8\"->larq) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4.0,>=2.0; python_version < \"3.8\"->larq) (3.7.4.3)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=14074e7061ab4a71cdeaaecd860f363959833afca588dc06704a98e41d8761b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, larq\n",
            "Successfully installed larq-0.10.3 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gOe_ITO-svj"
      },
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications as kapp, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import larq as lq\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVD4dXo5_Snv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7987a942-7388-4d66-c569-0b4d250998ea"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnF-kHUIAfLH"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saIiXQMm4P9l"
      },
      "source": [
        "x_test  = tf.image.resize(x_test, (96, 96), 'bicubic').numpy()\n",
        "x_train = tf.image.resize(x_train, (96, 96), 'bicubic').numpy()\n",
        "x_val = tf.image.resize(x_val, (96, 96), 'bicubic').numpy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwzmhlqDA_Np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af46ca67-eaf7-4b5d-83a7-7784725e2e1f"
      },
      "source": [
        "print(\"X_train.shape: {}\\tY_train.shape: {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"X_val.shape:   {}\\tY_val.shape:   {}\".format(x_val.shape, y_val.shape))\n",
        "print(\"X_test.shape:  {}\\tY_test.shape:  {}\".format(x_test.shape, y_test.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape: (45000, 96, 96, 3)\tY_train.shape: (45000, 1)\n",
            "X_val.shape:   (5000, 96, 96, 3)\tY_val.shape:   (5000, 1)\n",
            "X_test.shape:  (10000, 96, 96, 3)\tY_test.shape:  (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xAVoOVl_9sH"
      },
      "source": [
        "to_categorical = keras.utils.to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_quB16yBqq0"
      },
      "source": [
        "DataGen = keras.preprocessing.image.ImageDataGenerator\n",
        "\n",
        "transformations = {\n",
        "    'rotation_range': 30,\n",
        "    # 'featurewise_std_normalization': True,\n",
        "    # 'featurewise_center': True,\n",
        "    'zoom_range': .5,\n",
        "    'horizontal_flip': True,\n",
        "    # 'zca_whitening': True, \n",
        "    'width_shift_range': 10 / 32, \n",
        "    'height_shift_range': 10 /32, \n",
        "    # 'brightness_range': (0, .2), \n",
        "    'rescale': 1/255.,\n",
        "    'shear_range': .5,\n",
        "    # 'preprocessing_function': kapp.mobilenet_v2.preprocess_input\n",
        "}\n",
        "\n",
        "train_generator = DataGen(**transformations)\n",
        "val_generator   = DataGen(rescale=1/255., rotation_range=50, horizontal_flip=True, zoom_range=.5,\n",
        ")\n",
        "test_generator  = DataGen(rescale=1/255.)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4f2WCsdGp-j"
      },
      "source": [
        "# train_generator.fit(x_train)\n",
        "# val_generator.fit(x_val)\n",
        "# test_generator.fit(x_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Eu3o1O_o2z"
      },
      "source": [
        "# core_model = kapp.MobileNetV2()\n",
        "# core_model.summary()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdDSupPBHGSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dafae27-bd56-4267-bee0-cca3d69f9079"
      },
      "source": [
        "input_shape = (96, 96, 3)\n",
        "fine_tune = True\n",
        "# core_model = kapp.EfficientNetB0(x_train.shape[1:], weights='imagenet', include_top=False, classes=y_train.shape[-1])\n",
        "core_model = kapp.MobileNetV2(include_top=False, input_shape=input_shape, classes=y_train.shape[-1], weights='imagenet')\n",
        "core_model.trainable = fine_tune\n",
        "\n",
        "inputs = keras.layers.Input(shape=input_shape)\n",
        "\n",
        "# norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "# mean = np.array([127.5] * 3)\n",
        "# # print(mean)\n",
        "# var = mean ** 2\n",
        "# # Scale inputs to [-1, +1]\n",
        "# x = norm_layer(inputs)\n",
        "# norm_layer.set_weights([mean, var])\n",
        "\n",
        "# # x = core_model.output\n",
        "# x = core_model(x, training=False)\n",
        "x = core_model(inputs, training=fine_tune)\n",
        "x = keras.layers.Dropout(.3)(x)\n",
        "x = keras.layers.GlobalAveragePooling2D(name='global_average_pooling')(x)\n",
        "# x = keras.layers.Dense(512, activation='relu')(x)\n",
        "# x = keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
        "# x = keras.layers.Dropout(.35)(x)\n",
        "output = keras.layers.Dense(y_train.shape[-1], name='predictions', activation='softmax')(x)\n",
        "# x = keras.layers.Reshape((1, 1, -1))(x)\n",
        "# x = keras.layers.Dropout(.2, name='dropout', )(x)\n",
        "# x = keras.layers.Conv2D(filters = y_train.shape[-1], kernel_size=1, name='logits')(x)\n",
        "# x = keras.layers.Flatten()(x)\n",
        "# output = keras.layers.Activation('softmax', name='predictions')(x)\n",
        "\n",
        "# model = models.Model(inputs=core_model.input, outputs=output)\n",
        "model = models.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model.summary()\n",
        "print(len(model.layers))\n",
        "# lq.models.summary(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_96 (Functio (None, 3, 3, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 3, 1280)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling (Glob (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                12810     \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 2,236,682\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inNQRiv66f1J",
        "outputId": "78d243f0-1cbc-4a4e-cf7a-48c10a610d60"
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(core_model.layers))\n",
        "core_model.trainable = True\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "# fine_tune_at = 107\n",
        "# fine_tune_at = 81\n",
        "fine_tune_at = 0\n",
        "print(type(core_model.layers[fine_tune_at]))\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in core_model.layers[:fine_tune_at + 1]:\n",
        "  layer.trainable =  False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  154\n",
            "<class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_96 (Functio (None, 3, 3, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 3, 1280)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling (Glob (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                12810     \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 2,236,682\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4gmISRMrxA"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 1000\n",
        "initial_learning_rate = 0.0008\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate,\n",
        "#     decay_steps=100000,\n",
        "#     decay_rate=0.96,\n",
        "#     staircase=True)\n",
        "\n",
        "optimzer = keras.optimizers.Adam(initial_learning_rate)\n",
        "callbacks = [\n",
        "              keras.callbacks.EarlyStopping('val_accuracy', patience=10, verbose=1, restore_best_weights=True),\n",
        "              keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=.5, patience=6, verbose=1),\n",
        "              keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4', monitor='val_accuracy', save_best_only=True)\n",
        "]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mvG0JJBSXAb"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFWx9GKZUoxR"
      },
      "source": [
        "# model_2 = keras.models.load_model('/content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_2')\n",
        "model_2 = keras.models.load_model('mobilenetv2_temp')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgFoDWLgOKM_"
      },
      "source": [
        "model.compile(optimizer=optimzer, loss='categorical_crossentropy', metrics=['accuracy'], )"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eqmFy1B2MLt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5866fc03-00f0-49ea-e747-263c51985762"
      },
      "source": [
        "model.fit(\n",
        "    train_generator.flow(x_train, y_train, batch_size),\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    validation_data=val_generator.flow(x_val, y_val, batch_size),\n",
        "    validation_steps=x_val.shape[0] // batch_size,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "175/175 [==============================] - 170s 971ms/step - loss: 0.2922 - accuracy: 0.8989 - val_loss: 0.4300 - val_accuracy: 0.8581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/1000\n",
            "175/175 [==============================] - 169s 962ms/step - loss: 0.2844 - accuracy: 0.8994 - val_loss: 0.4244 - val_accuracy: 0.8577\n",
            "Epoch 3/1000\n",
            "175/175 [==============================] - 168s 955ms/step - loss: 0.2734 - accuracy: 0.9032 - val_loss: 0.4100 - val_accuracy: 0.8614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/1000\n",
            "175/175 [==============================] - 167s 953ms/step - loss: 0.2718 - accuracy: 0.9063 - val_loss: 0.4167 - val_accuracy: 0.8629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/1000\n",
            "175/175 [==============================] - 168s 955ms/step - loss: 0.2629 - accuracy: 0.9095 - val_loss: 0.4246 - val_accuracy: 0.8592\n",
            "Epoch 6/1000\n",
            "175/175 [==============================] - 167s 952ms/step - loss: 0.2633 - accuracy: 0.9072 - val_loss: 0.4198 - val_accuracy: 0.8649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/1000\n",
            "175/175 [==============================] - 166s 947ms/step - loss: 0.2555 - accuracy: 0.9104 - val_loss: 0.4166 - val_accuracy: 0.8590\n",
            "Epoch 8/1000\n",
            "175/175 [==============================] - 168s 960ms/step - loss: 0.2576 - accuracy: 0.9105 - val_loss: 0.4203 - val_accuracy: 0.8563\n",
            "Epoch 9/1000\n",
            "175/175 [==============================] - 168s 955ms/step - loss: 0.2528 - accuracy: 0.9107 - val_loss: 0.4074 - val_accuracy: 0.8614\n",
            "Epoch 10/1000\n",
            "175/175 [==============================] - 170s 969ms/step - loss: 0.2451 - accuracy: 0.9140 - val_loss: 0.4320 - val_accuracy: 0.8586\n",
            "Epoch 11/1000\n",
            "175/175 [==============================] - 168s 956ms/step - loss: 0.2486 - accuracy: 0.9140 - val_loss: 0.4176 - val_accuracy: 0.8643\n",
            "Epoch 12/1000\n",
            "175/175 [==============================] - 170s 970ms/step - loss: 0.2339 - accuracy: 0.9182 - val_loss: 0.4222 - val_accuracy: 0.8641\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 13/1000\n",
            "175/175 [==============================] - 169s 964ms/step - loss: 0.2363 - accuracy: 0.9177 - val_loss: 0.4112 - val_accuracy: 0.8703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/0Works/cooparetive/MobilenetV2alpha1_4/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/1000\n",
            "175/175 [==============================] - 169s 961ms/step - loss: 0.2355 - accuracy: 0.9179 - val_loss: 0.4252 - val_accuracy: 0.8616\n",
            "Epoch 15/1000\n",
            "175/175 [==============================] - 166s 945ms/step - loss: 0.2381 - accuracy: 0.9157 - val_loss: 0.4384 - val_accuracy: 0.8544\n",
            "Epoch 16/1000\n",
            "175/175 [==============================] - 164s 936ms/step - loss: 0.2388 - accuracy: 0.9160 - val_loss: 0.4374 - val_accuracy: 0.8536\n",
            "Epoch 17/1000\n",
            "175/175 [==============================] - 165s 938ms/step - loss: 0.2321 - accuracy: 0.9177 - val_loss: 0.4142 - val_accuracy: 0.8608\n",
            "Epoch 18/1000\n",
            "175/175 [==============================] - 165s 942ms/step - loss: 0.2332 - accuracy: 0.9178 - val_loss: 0.4136 - val_accuracy: 0.8625\n",
            "Epoch 19/1000\n",
            "175/175 [==============================] - 166s 944ms/step - loss: 0.2315 - accuracy: 0.9195 - val_loss: 0.4025 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "Epoch 20/1000\n",
            "175/175 [==============================] - 165s 939ms/step - loss: 0.2347 - accuracy: 0.9194 - val_loss: 0.4276 - val_accuracy: 0.8641\n",
            "Epoch 21/1000\n",
            " 61/175 [=========>....................] - ETA: 1:40 - loss: 0.2380 - accuracy: 0.9184"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-21a244676d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwmuLdJ9o_kl",
        "outputId": "2a196520-34ce-407e-8051-7b1559381248"
      },
      "source": [
        "model.evaluate(test_generator.flow(x_test, y_test, batch_size=batch_size))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 6s 155ms/step - loss: 0.2390 - accuracy: 0.9166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2390439659357071, 0.9165999889373779]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWjk11M7SCRT",
        "outputId": "be653362-ebb6-4b34-b83e-0fcbd90ecf1b"
      },
      "source": [
        "model.save('mobilnetV2alpha1')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses, expanded_conv_depthwise_relu_layer_call_fn while saving (showing 5 of 400). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: mobilnetV2alpha1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: mobilnetV2alpha1/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}